# timepoint_order <- temp_condition_names
# replicate_order <- c("r1", "r2")
# plot_shapes <- FALSE
# legend_position <- "none"
# centroid_labels <- TRUE
# point_size <- 1
# centroid_label_size <- 1
# PCA_depths_y <- c(2, 3, 4)
# PCA_depths_x <- c(1, 2, 3)
# input_colour_limits <- tibble_sharp_cluster_mapping$condition_names
# tibble_colour_metadata <- tibble_sharp_cluster_mapping %>% dplyr::ungroup() %>% dplyr::rename("som_cluster" = "cluster", "input_colour_limits" = "condition_names") %>% dplyr::select(id, som_cluster, input_colour_limits, Description, Biological_source, Type) %>% dplyr::mutate_at(.vars = c("Description", "Biological_source", "Type"), .funs = function(x) {gsub(x = x, pattern = "[^a-zA-Z0-9 -/]", replacement = "")})
# input_colour_value = rainbow(tibble_sharp_cluster_mapping$cluster %>% max) %>% .[tibble_sharp_cluster_mapping$cluster]
# save_dir <- R_processing_results_dir
# save_name <- paste("atlas_polya_psisigma_consensus_som_clusterone_with_na_plotly", sep = "")
# graph_title = "PolyA/PSI-Sigma w/ replicates, coloured by consensus SOM clusters"
# width <- 40
# height <- 40
###########
tibble_tsne_result <- Rtsne::Rtsne(X = transposed_matrixtable %>% unique, perplexity = 1, check_duplicates = FALSE, verbose = TRUE, num_threads = 0) %>% .$Y %>%
as_tibble(.name_repair = "unique") %>%
add_column("condition_names" = rownames(transposed_matrixtable %>% unique), .before = 1) %>%
setNames(nm = c("condition|replicate", "V1", "V2")) %>%
add_column("condition_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\1"),
"replicate_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\2")
)
# centroid labels: make a separate file containing the centroid locations
tibble_centroid_locations <- tibble_tsne_result %>%
dplyr::group_by(condition_names) %>%
dplyr::summarise("centroid_x" = mean(V1),
"centroid_y" = mean(V2)) %>%
add_column("cluster_number" = paste(1:nrow(.)), .after = "condition_names")
tibble_colour_metadata <- tibble_colour_metadata[match(tibble_centroid_locations$condition_names, tibble_colour_metadata$input_colour_limits), ]
# append cluster info
tibble_tsne_result_plot <- dplyr::left_join(tibble_tsne_result, tibble_centroid_locations, by = "condition_names")
if (is.null(input_colour_limits) == TRUE) {
input_colour_limits <- c(tibble_tsne_result_plot$condition_names %>% unique)
}
if (is.null(input_colour_value) == TRUE) {
input_colour_value <- rainbow(n = (timepoint_order %>% length))
}
# plot UMAP for multiple depths all in one go.
ggplot_plot <- ggplot() +
(if (plot_shapes == TRUE) {geom_point(aes(x = tibble_tsne_result_plot$V1, y = tibble_tsne_result_plot$V2, shape = tibble_tsne_result_plot$replicate_names, color = tibble_tsne_result_plot$condition_names, fill = tibble_tsne_result_plot$condition_names), size = point_size) } else {geom_blank(aes(x = tibble_tsne_result_plot$V1, y = tibble_tsne_result_plot$V2))}) +
scale_shape_manual(name = "Replicate", values = 1:length(replicate_order)) +
(if (centroid_labels == TRUE) {geom_text(data = tibble_centroid_locations, aes(x = centroid_x, y = centroid_y, label = cluster_number, color = condition_names, som_cluster = tibble_colour_metadata$som_cluster, Description = tibble_colour_metadata$Description, Biological_source = tibble_colour_metadata$Biological_source, Type = tibble_colour_metadata$Type), size = centroid_label_size)} else {geom_blank(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y))}) +
scale_fill_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
scale_colour_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
# scale_color_brewer(name = "Timepoint", palette = "Spectral", breaks = timepoint_order, limits = timepoint_order) +
ggtitle(paste("UMAP projection\n", graph_title, sep = "")) +
guides(som_cluster = guide_legend(order = 1)) +
# guides(size = FALSE) +
xlab("UMAP_1") +
ylab("UMAP_2") +
theme_bw() +
theme(text = element_text(family = "Helvetica"), legend.position = legend_position)
plotly::ggplotly(
p = ggplot_plot,
width = NULL,
height = NULL,
tooltip = "all",
dynamicTicks = FALSE,
layerData = "Timepoint",
originalData = TRUE,
) %>%
htmlwidgets::saveWidget(paste(save_dir, "/", save_name, ".html", sep = ""))
ggsave(plot = ggplot_plot, filename = paste(save_dir, "/", save_name, ".pdf", sep = ""), device = "pdf", dpi = 600, width = width, height = height, units = "cm")
# ggsave(plot = ggplot_plot, filename = paste(save_dir, "/", save_name, ".svg", sep = ""), device = "svg", dpi = 600, width = width, height = height, units = "cm")
write.table(x = tibble_centroid_locations, file = paste(save_dir, "/", save_name, "_cluster_legend.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)
}
library(rrvgo)
library(org.Hs.eg.db)
# load catdb
load(paste(reference_data_dir, "polyA_RNAseq_GO_background_GOTERM.catdb", sep = ""))
tibble_characteristic_markers_for_each_som_cluster_hypergo <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_characteristic_markers_for_each_som_cluster_hypergo.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, header = TRUE) %>% as_tibble
tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0 <- tibble_characteristic_markers_for_each_som_cluster_hypergo %>%
dplyr::filter(Padj <= 0.05) %>%
dplyr::group_by(GOID, NodeSize, Term, Ont) %>%
dplyr::summarise("Padj_aggregate" = sum(-log(Padj))) %>%
dplyr::ungroup()
# import go term hierarchy table
tibble_go_hierarchy0 <- data.table::fread(file = paste(reference_data_dir, "tibble_go_hierarchy_final.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, header = TRUE, na.strings = c("na", "NA", "")) %>% tibble::as_tibble()
tibble_go_hierarchy <- tibble_go_hierarchy0 %>% dplyr::distinct(id, parent_id, .keep_all = FALSE)
future::plan(future::multicore)
options(mc.cores = 96)
list_goterm_simplication_results <- furrr::future_imap(
.x = tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0 %>% dplyr::rowwise() %>% dplyr::group_split(),
.f = function(a1, a2) {
# DEBUG ###
# a1 <- tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0 %>% dplyr::rowwise() %>% dplyr::group_split() %>% .[[750]]
###########
cat(a2, "\n")
list_current_entries_considered <- list(a1)
# find the child entropy
## lookup original enrichment table for the children's enrichments
list_enrichments_of_initial_children <- purrr::map(
.x = list_current_entries_considered %>% purrr::map(~.x$GOID),
.f = function(b1) {
return(
list(
"enrichment_match" = tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0[tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0$GOID %in% (tibble_go_hierarchy[tibble_go_hierarchy$parent_id == b1, ] %>% .$id), ],
"vector_other_peers_with_no_match" = (tibble_go_hierarchy[tibble_go_hierarchy$parent_id == b1, ] %>% .$id) %>% .[!. %in% tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0$GOID]
)
)
} )
## calculate the child relative entropy
list_entropy_result_children <- purrr::map2(
.x = list_enrichments_of_initial_children,
.y = list_current_entries_considered,
.f = function(b1, b2) {
# DEBUG ###
# b1 <- list_enrichments_of_initial_children[[1]]
# b2 <- list_current_entries_considered[[1]]
###########
# if no initial children, then set entropy to 99 because this would be the lowest level enriched.
if (nrow(b1$enrichment_match) == 0 & length(b1$vector_other_peers_with_no_match) == 0) {
entropy_factor <- 99
} else {
entropy_factor <- purrr::map(
.x = c(b1$enrichment_match$Padj_aggregate, rep(1, times = length(b1$vector_other_peers_with_no_match))),
.f = ~log(.x)
) %>% unlist %>% sum
entropy_factor <- entropy_factor * (1/length(c(b1$enrichment_match$Padj_aggregate, rep(1, times = length(b1$vector_other_peers_with_no_match)))))
}
return(
"entropy_factor" = entropy_factor
)
} )
temp_continuing <- TRUE
master_tibble_parent_entries <- tibble()
# BEGIN LOOP
while (temp_continuing == TRUE) {
print("entropy factor: children")
print(str(list_entropy_result_children))
# fetch parent IDs based on current enrichment entries
list_vector_parents <- purrr::map(
.x = list_current_entries_considered,
.f = ~tibble_go_hierarchy[tibble_go_hierarchy$id == .x$GOID, ] %>% .$parent_id
) %>%
# account for scenario where there are no parents. we have to make tibble anyways
purrr::map_if(.p = ~.x %>% length == 0, .f = ~tibble())
# lookup original enrichment table for the parents' enrichments
list_enrichments_of_parents <- purrr::map(
.x = list_vector_parents,
.f = function(b1) {
purrr::map(
.x = b1,
.f = function(c1) {
tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0[tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0$GOID == c1, ] %>% return
}
) %>% return
} )
list_enrichments_of_all_peers <- purrr::map(
.x = list_vector_parents,
.f = function(b1) {
purrr::map(
.x = b1,
.f = function(c1) {
return(
list(
"enrichment_match" = tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0[tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0$GOID %in% (tibble_go_hierarchy[tibble_go_hierarchy$parent_id == c1, ] %>% .$id), ],
"vector_other_peers_with_no_match" = (tibble_go_hierarchy[tibble_go_hierarchy$parent_id == c1, ] %>% .$id) %>% .[!. %in% tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0$GOID]
)
)
} ) %>% return
} )
# get entropy result from the child terms of parents
# NOTE: if child term didn't exist in the enrichment, then its p-value is considered to be 1.
list_entropy_result_peers <- purrr::map2(
.x = list_enrichments_of_all_peers,
.y = list_current_entries_considered,
.f = function(b1, b2) {
# DEBUG ###
# b1 <- list_enrichments_of_all_peers[[1]]
# b2 <- list_current_entries_considered[[1]]
###########
purrr::map(
.x = b1,
.f = function(c1) {
# DEBUG ###
# c1 <- b1[[1]]
###########
# q_value <- if (c1$enrichment_match %>% nrow > 0) {stats::p.adjust(p = c1$enrichment_match$Padj_aggregate, method = "BH") %>% .[c1$enrichment_match$GOID == b2$GOID] %>% return} else {NA}
#
# entropy_factor <- purrr::map(
#   .x = c(c1$enrichment_match$Padj_aggregate %>% .[. > q_value], rep(1, times = length(c1$vector_other_peers_with_no_match))),
#   .f = ~.x * log(.x * q_value, base = q_value)
# ) %>% unlist %>% sum()
entropy_factor <- purrr::map(
.x = c(c1$enrichment_match$Padj_aggregate, rep(1, times = length(c1$vector_other_peers_with_no_match))),
.f = ~log(.x)
) %>% unlist %>% sum
entropy_factor <- entropy_factor * (1/length(c(c1$enrichment_match$Padj_aggregate, rep(1, times = length(c1$vector_other_peers_with_no_match)))))
return(
"entropy_factor" = entropy_factor
)
} ) %>% return
} )
print("entropy factor: peers")
print(str(list_entropy_result_peers))
# if TRUE, then entropy of peers is smaller than entropy of children. This means that taking the parent was worth it.
# This also means that we will have to keep moving upwards thru those parents.
# here, we account for the case that we don't have any parents enriched
list_entropy_children_vs_peers <- purrr::pmap(
.l = list(
"b1" = list_entropy_result_peers,
"b2" = list_entropy_result_children,
"b3" = list_enrichments_of_parents
),
.f = function(b1, b2, b3) {
# DEBUG ###
# b1 <- list_entropy_result_peers[[3]]
# b2 <- list_entropy_result_children[[3]]
# b3 <- list_enrichments_of_parents[[3]]
###########
purrr::pmap(
.l = list(
"c1" = b1,
"c3" = b3
),
.f = function(c1, c3) {
if (nrow(c3) == 0) {
return(FALSE)
} else {
return(c1 < b2)
}
} ) %>% return
} )
if (any(list_entropy_children_vs_peers %>% unlist) == TRUE) {
temp_continuing <- TRUE
# add the terminated entries to master tibble
## terminated entries occur when the peer entropy becomes higher than the child entropy.
## This means it no longer makes sense to take the parent.
master_tibble_parent_entries <- dplyr::bind_rows(
master_tibble_parent_entries,
list_current_entries_considered[list_entropy_children_vs_peers %>% purrr::map(~any(.x %>% unlist == FALSE)) %>% unlist] %>% data.table::rbindlist(use.names = TRUE, fill = TRUE) %>% tibble::add_column("seed" = a1$GOID, "terminal_type" = "node") %>% tibble::as_tibble()
)
} else {
temp_continuing <- FALSE
# add the leaves to the master tibble because these are the true terminal parent entries.
master_tibble_parent_entries <- dplyr::bind_rows(
master_tibble_parent_entries,
list_current_entries_considered[list_entropy_children_vs_peers %>% purrr::map(~any(.x %>% unlist == FALSE)) %>% unlist] %>% data.table::rbindlist(use.names = TRUE, fill = TRUE) %>% tibble::add_column("seed" = a1$GOID, "terminal_type" = "leaf") %>% tibble::as_tibble()
)
}
print("temp_continuing:")
print(temp_continuing)
# un-nest parent entries and assign them to the next round of current entries
# NOTE: this is because we can have *multiple* child inputs to begin with; and MULTIPLE possible parents from each.
list_current_entries_considered <- purrr::map2(
.x = list_entropy_children_vs_peers,
.y = list_enrichments_of_parents,
.f = function(b1, b2) {
# DEBUG ###
# b1 <- list_entropy_children_vs_peers[[1]]
# b2 <- list_enrichments_of_parents[[1]]
###########
list_continuing_parent_entries <- b2[b1 %>% unlist]
return(list_continuing_parent_entries)
} ) %>% purrr::flatten() %>%
purrr::discard(.p = ~.x %>% nrow == 0)
# un-nesst peer entropy and use as children for the next round
list_entropy_result_children <- purrr::map2(
.x = list_entropy_children_vs_peers,
.y = list_entropy_result_peers,
.f = function(b1, b2) {
# DEBUG ###
# b1 <- list_entropy_children_vs_peers[[1]]
# b2 <- list_enrichments_of_parents[[1]]
###########
list_continuing_parent_entropies <- b2[b1 %>% unlist]
return(list_continuing_parent_entropies)
} ) %>% purrr::flatten()
}
# remove duplicate parents, especially node versions if there is already a leaf available.
master_tibble_parent_entries_filtered <- dplyr::bind_rows(
master_tibble_parent_entries[master_tibble_parent_entries$terminal_type == "node", ] %>% .[!.$Term %in% (master_tibble_parent_entries[master_tibble_parent_entries$terminal_type == "leaf", ] %>% .$Term), ],
master_tibble_parent_entries[master_tibble_parent_entries$terminal_type == "leaf", ]
) %>% dplyr::distinct(.keep_all = TRUE)
return(master_tibble_parent_entries_filtered)
}, .progress = TRUE )
tibble_goterm_simplication_results <- list_goterm_simplication_results %>%
data.table::rbindlist(use.names = TRUE, fill = TRUE) %>%
tibble::as_tibble() %>%
dplyr::bind_rows(., tibble_characteristic_markers_for_each_som_cluster_hypergo_summarised0 %>% tibble::add_column("seed" = "none", "terminal_type" = "seed")) %>%
dplyr::distinct(GOID, .keep_all = TRUE) %>%
dplyr::group_by(GOID, NodeSize, Term, Ont, Padj_aggregate, terminal_type) %>%
dplyr::summarise("seeds" = paste(`seed`, collapse = ",")) %>%
# add depth
dplyr::left_join(., tibble_go_hierarchy0[, c("id", "id_depth", "parent_id", "parent_id_depth", "depth_proximity")] %>% unique %>% dplyr::rename("GOID" = "id"))
write.table(x = tibble_goterm_simplication_results, file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_goterm_simplication_results.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)
# tibble_goterm_simplication_results <- data.table::fread(file = paste(R_processing_results_dir, vector_experiment_metadata_main %>% paste(collapse = "_"), "_tibble_goterm_simplication_results.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, header = TRUE) %>% tibble::as_tibble()
shiny::runApp('/mnt/LTS/projects/2020_isoform_nomenclature/nomenclature_app/app_native/EDN_suite')
global_tibble_user_ranges_visible
global_list_tibbles_track_features_visible_flattened
global_2_list_tibbles_track_features_visible_flattened
a1 <- global_1_list_tibbles_track_features_visible_flattened[[1]]
a2 <- names(global_1_list_tibbles_track_features_visible_flattened)[[1]]
a3 <- global_1_list_tibbles_track_features_all_flattened[gsub(x = global_1_list_tibbles_track_features_visible_flattened %>% names, pattern = "^[^\\:]+\\: (.*)", replacement = "\\1")] %>% .[[1]]
selected_user_range_chr <- global_selected_user_range_chr
selected_user_range_start <- global_selected_user_range_start
selected_user_range_end <- global_selected_user_range_end
global_selected_user_range_chr
## having determined the plot window, calculate distances to every exon in the plot range
list_distance_annotation_data_flattened <- purrr::pmap(
.l = list(
"a1" = list_tibbles_track_features_visible_flattened,
"a2" = names(list_tibbles_track_features_visible_flattened),
"a3" = list_tibbles_track_features_all_flattened[gsub(x = list_tibbles_track_features_visible_flattened %>% names, pattern = "^[^\\:]+\\: (.*)", replacement = "\\1")]
),
.f = function(a1, a2, a3) {
# DEBUG ###
# a1 <- global_1_list_tibbles_track_features_visible_flattened[[1]]
# a2 <- names(global_1_list_tibbles_track_features_visible_flattened)[[1]]
# a3 <- global_1_list_tibbles_track_features_all_flattened[gsub(x = global_1_list_tibbles_track_features_visible_flattened %>% names, pattern = "^[^\\:]+\\: (.*)", replacement = "\\1")] %>% .[[1]]
# selected_user_range_chr <- global_selected_user_range_chr
# selected_user_range_start <- global_selected_user_range_start
# selected_user_range_end <- global_selected_user_range_end
###########
# determine visible transcript ids overlapped by user range
tibble_ref_transcripts_overlapped_by_user_query <- extract_overlapping_features(query_chr = selected_user_range_chr, query_start = selected_user_range_start, query_end = selected_user_range_end, query_strand = "*", tibble_gtf_table = a1, left_query_shift = input$workshop_left_query_end_shift %>% type.convert, right_query_shift = input$workshop_right_query_end_shift %>% type.convert, left_tolerance = input$workshop_left_match_tolerance %>% type.convert, right_tolerance = input$workshop_right_match_tolerance %>% type.convert, return_type = if (grepl(x = a2, pattern = "Reference protein") == TRUE) {"exon"} else {"transcript"})
print("tibble_ref_transcripts_overlapped_by_user_query")
print(tibble_ref_transcripts_overlapped_by_user_query)
query_width <- selected_user_range_end - selected_user_range_start + 1
# check if the selected transcript overlaps a ref transcript
if (tibble_ref_transcripts_overlapped_by_user_query %>% nrow > 0) {
tibble_all_exons_of_overlapped_parent_transcript <- a3[which(a3$type == "exon" & a3$transcript_id %in% (tibble_ref_transcripts_overlapped_by_user_query$transcript_id %>% unique)), ]
print("tibble_all_exons_of_overlapped_parent_transcript")
print(tibble_all_exons_of_overlapped_parent_transcript)
# for interpro/biomart, split by **id** (rowwise) due to plotting of one feature at a time.
if (grepl(x = a2, pattern = "Reference protein.*interpro") == TRUE) {
tibble_distance_annotations_based_on_user_query <- purrr::map(
# individual protein domains/regions
.x = tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(id),
.f = function(b1) {
# DEBUG ###
# b1 <- tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(id) %>% .[[1]]
###########
vector_all_ref_vertices <- b1[, c("start", "end")] %>% unlist %>% sort
# strategy: grow left and right ends of the user vertices until it touches a vertex.
left_ref_vertex_grown_from_user_query_start <- vector_all_ref_vertices[vector_all_ref_vertices <= selected_user_range_start] %>% max
right_ref_vertex_grown_from_user_query_start <- vector_all_ref_vertices[vector_all_ref_vertices >= selected_user_range_start] %>% min
left_ref_vertex_grown_from_user_query_end <- vector_all_ref_vertices[vector_all_ref_vertices <= selected_user_range_end] %>% max
right_ref_vertex_grown_from_user_query_end <- vector_all_ref_vertices[vector_all_ref_vertices >= selected_user_range_end] %>% min
tibble_vertices_with_distances <- tibble(
"id" = b1$id %>% unique,
"protein_id" = b1$protein_id %>% unique,
"ref_vertex" = c(left_ref_vertex_grown_from_user_query_start, right_ref_vertex_grown_from_user_query_start, left_ref_vertex_grown_from_user_query_end, right_ref_vertex_grown_from_user_query_end),
"query_vertex" = c(selected_user_range_start, selected_user_range_start, selected_user_range_end, selected_user_range_end)
) %>% dplyr::mutate("ref_vertex_minus_query_vertex" = `ref_vertex` - `query_vertex`) %>%
.[is.finite(.$ref_vertex_minus_query_vertex), ]
# test for redundant overlapping distances. this happens when 1. both query ends find a ref transcript and 2. distance to left overlaps and/or distance to right overlaps.
if (left_ref_vertex_grown_from_user_query_end < selected_user_range_start) {
tibble_vertices_with_distances <- tibble_vertices_with_distances[!(tibble_vertices_with_distances$ref_vertex == left_ref_vertex_grown_from_user_query_end & tibble_vertices_with_distances$query_vertex == selected_user_range_end), ]
}
if (right_ref_vertex_grown_from_user_query_start > selected_user_range_end) {
tibble_vertices_with_distances <- tibble_vertices_with_distances[!(tibble_vertices_with_distances$ref_vertex == right_ref_vertex_grown_from_user_query_start & tibble_vertices_with_distances$query_vertex == selected_user_range_start), ]
}
# now calculate the % overlaps.
## note that we are only going to show the percentage overlap for partially overlapped exons/features on the ends - the exons in the middle are implied.
## 1. add in the ref exon start/end entries that are associated with each ref_vertex
tibble_vertices_with_pct_overlap <- dplyr::bind_cols(
tibble_vertices_with_distances,
purrr::map(.x = tibble_vertices_with_distances$ref_vertex, .f = ~b1[which(b1$start == .x | b1$end == .x), c("start", "end")]) %>% dplyr::bind_rows() %>% dplyr::rename("ref_exon_start" = "start", "ref_exon_end" = "end")
)
## 2. check if each feature overlapped by the query range
tibble_vertices_with_pct_overlap <- tibble_vertices_with_pct_overlap %>%
dplyr::mutate("is_overlapped" = ((query_vertex + input$workshop_left_query_end_shift %>% type.convert - input$workshop_left_match_tolerance %>% type.convert) <= ref_exon_end) & ((query_vertex + input$workshop_left_query_end_shift %>% type.convert - input$workshop_left_match_tolerance %>% type.convert) >= ref_exon_start)
)
tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == TRUE, "pct_overlap"] <- tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == TRUE, ] %>% ( function(x) {100 * abs(x$query_vertex - x$ref_vertex)/(x$ref_exon_end - x$ref_exon_start) %>% return} )
# tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == TRUE, "pct_overlap"] <- tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == TRUE, ] %>% purrr::map2(.x = .$ref_exon_start, .y = .$ref_exon_end, .f = ~min(100*c(abs(.y - selected_user_range_start), abs(selected_user_range_end - .x))/(.y - .x))) %>% unlist
tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == FALSE, "pct_overlap"] <- 0
return(tibble_vertices_with_pct_overlap)
} ) %>% dplyr::bind_rows() %>% unique
# for dbPTM, split by protein_id
} else if (grepl(x = a2, pattern = "Reference protein.*ptm") == TRUE) {
tibble_distance_annotations_based_on_user_query <- purrr::map2(
# overlapping transcript entries
.x = tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(protein_id),
# exons belonging to the transcript
.y = tibble_all_exons_of_overlapped_parent_transcript %>% dplyr::group_split(protein_id) %>% set_names(nm = purrr::map(.x = ., .f = ~.x$protein_id %>% unique) %>% unlist) %>% .[tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(protein_id) %>% purrr::map(~.x$protein_id %>% unique) %>% unlist],
.f = function(b1, b2) {
# DEBUG ###
# b1 <- tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(protein_id) %>% .[[2]]
# b2 <- tibble_all_exons_of_overlapped_parent_transcript %>% dplyr::group_split(protein_id) %>% set_names(nm = purrr::map(.x = ., .f = ~.x$protein_id %>% unique) %>% unlist) %>% .[tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(protein_id) %>% purrr::map(~.x$protein_id %>% unique) %>% unlist] %>% .[[2]]
###########
vector_all_ref_vertices <- b2[, c("start", "end")] %>% unlist %>% sort
# strategy: grow left and right ends of the user vertices until it touches a vertex.
left_ref_vertex_grown_from_user_query_start <- vector_all_ref_vertices[vector_all_ref_vertices <= selected_user_range_start] %>% max
right_ref_vertex_grown_from_user_query_start <- vector_all_ref_vertices[vector_all_ref_vertices >= selected_user_range_start] %>% min
left_ref_vertex_grown_from_user_query_end <- vector_all_ref_vertices[vector_all_ref_vertices <= selected_user_range_end] %>% max
right_ref_vertex_grown_from_user_query_end <- vector_all_ref_vertices[vector_all_ref_vertices >= selected_user_range_end] %>% min
tibble_vertices_with_distances <- tibble(
"protein_id" = b1$protein_id %>% unique,
"ref_vertex" = c(left_ref_vertex_grown_from_user_query_start, right_ref_vertex_grown_from_user_query_start, left_ref_vertex_grown_from_user_query_end, right_ref_vertex_grown_from_user_query_end),
"query_vertex" = c(selected_user_range_start, selected_user_range_start, selected_user_range_end, selected_user_range_end)
) %>% dplyr::mutate("ref_vertex_minus_query_vertex" = `ref_vertex` - `query_vertex`) %>%
.[is.finite(.$ref_vertex_minus_query_vertex), ]
# test for redundant overlapping distances. this happens when 1. both query ends find a ref transcript and 2. distance to left overlaps and/or distance to right overlaps.
if (left_ref_vertex_grown_from_user_query_end < selected_user_range_start) {
tibble_vertices_with_distances <- tibble_vertices_with_distances[!(tibble_vertices_with_distances$ref_vertex == left_ref_vertex_grown_from_user_query_end & tibble_vertices_with_distances$query_vertex == selected_user_range_end), ]
}
if (right_ref_vertex_grown_from_user_query_start > selected_user_range_end) {
tibble_vertices_with_distances <- tibble_vertices_with_distances[!(tibble_vertices_with_distances$ref_vertex == right_ref_vertex_grown_from_user_query_start & tibble_vertices_with_distances$query_vertex == selected_user_range_start), ]
}
# now calculate the % overlaps.
## note that we are only going to show the percentage overlap for partially overlapped exons/features on the ends - the exons in the middle are implied.
## 1. add in the ref exon start/end entries that are associated with each ref_vertex
tibble_vertices_with_pct_overlap <- dplyr::bind_cols(
tibble_vertices_with_distances,
purrr::map(.x = tibble_vertices_with_distances$ref_vertex, .f = ~b2[which(b2$start == .x | b2$end == .x), c("start", "end")]) %>% dplyr::bind_rows() %>% dplyr::rename("ref_exon_start" = "start", "ref_exon_end" = "end")
)
## 2. check if each feature overlapped by the query range
tibble_vertices_with_pct_overlap <- tibble_vertices_with_pct_overlap %>%
dplyr::mutate("is_overlapped" = ((query_vertex + input$workshop_left_query_end_shift %>% type.convert - input$workshop_left_match_tolerance %>% type.convert) <= ref_exon_end) & ((query_vertex + input$workshop_left_query_end_shift %>% type.convert - input$workshop_left_match_tolerance %>% type.convert) >= ref_exon_start)
)
tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == TRUE, "pct_overlap"] <- tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == TRUE, ] %>% ( function(x) {100 * abs(x$query_vertex - x$ref_vertex)/(x$ref_exon_end - x$ref_exon_start) %>% return} )
tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == FALSE, "pct_overlap"] <- 0
return(tibble_vertices_with_pct_overlap)
} ) %>% dplyr::bind_rows() %>% unique
} else {
tibble_distance_annotations_based_on_user_query <- purrr::map2(
# overlapping transcript entries
.x = tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(transcript_id),
# exons belonging to the transcript
.y = tibble_all_exons_of_overlapped_parent_transcript %>% dplyr::group_split(transcript_id) %>% set_names(nm = purrr::map(.x = ., .f = ~.x$transcript_id %>% unique) %>% unlist) %>% .[tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(transcript_id) %>% purrr::map(~.x$transcript_id %>% unique) %>% unlist],
.f = function(b1, b2) {
# DEBUG ###
# b1 <- tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(transcript_id) %>% .[[1]]
# b2 <- tibble_all_exons_of_overlapped_parent_transcript %>% dplyr::group_split(transcript_id) %>% set_names(nm = purrr::map(.x = ., .f = ~.x$transcript_id %>% unique) %>% unlist) %>% .[tibble_ref_transcripts_overlapped_by_user_query %>% dplyr::group_split(transcript_id) %>% purrr::map(~.x$transcript_id %>% unique) %>% unlist] %>% .[[1]]
###########
vector_all_ref_vertices <- b2[, c("start", "end")] %>% unlist %>% sort
# strategy: grow left and right ends of the user vertices until it touches a vertex.
left_ref_vertex_grown_from_user_query_start <- vector_all_ref_vertices[vector_all_ref_vertices <= selected_user_range_start] %>% max
right_ref_vertex_grown_from_user_query_start <- vector_all_ref_vertices[vector_all_ref_vertices >= selected_user_range_start] %>% min
left_ref_vertex_grown_from_user_query_end <- vector_all_ref_vertices[vector_all_ref_vertices <= selected_user_range_end] %>% max
right_ref_vertex_grown_from_user_query_end <- vector_all_ref_vertices[vector_all_ref_vertices >= selected_user_range_end] %>% min
tibble_vertices_with_distances <- tibble(
"transcript_id" = b1$transcript_id %>% unique,
"ref_vertex" = c(left_ref_vertex_grown_from_user_query_start, right_ref_vertex_grown_from_user_query_start, left_ref_vertex_grown_from_user_query_end, right_ref_vertex_grown_from_user_query_end),
"query_vertex" = c(selected_user_range_start, selected_user_range_start, selected_user_range_end, selected_user_range_end)
) %>% dplyr::mutate("ref_vertex_minus_query_vertex" = `ref_vertex` - `query_vertex`) %>%
.[is.finite(.$ref_vertex_minus_query_vertex), ]
# test for redundant overlapping distances. this happens when 1. both query ends find a ref transcript and 2. distance to left overlaps and/or distance to right overlaps.
if (left_ref_vertex_grown_from_user_query_end < selected_user_range_start) {
tibble_vertices_with_distances <- tibble_vertices_with_distances[!(tibble_vertices_with_distances$ref_vertex == left_ref_vertex_grown_from_user_query_end & tibble_vertices_with_distances$query_vertex == selected_user_range_end), ]
}
if (right_ref_vertex_grown_from_user_query_start > selected_user_range_end) {
tibble_vertices_with_distances <- tibble_vertices_with_distances[!(tibble_vertices_with_distances$ref_vertex == right_ref_vertex_grown_from_user_query_start & tibble_vertices_with_distances$query_vertex == selected_user_range_start), ]
}
tibble_vertices_with_distances <- tibble_vertices_with_distances %>% unique
# now calculate the % overlaps.
## note that we are only going to show the percentage overlap for partially overlapped exons/features on the ends - the exons in the middle are implied.
## 1. add in the ref exon start/end entries that are associated with each ref_vertex
tibble_vertices_with_pct_overlap <- dplyr::bind_cols(
tibble_vertices_with_distances,
purrr::map(.x = tibble_vertices_with_distances$ref_vertex, .f = ~b2[which(b2$start == .x | b2$end == .x), c("start", "end")]) %>% dplyr::bind_rows() %>% dplyr::rename("ref_exon_start" = "start", "ref_exon_end" = "end")
)
## 2. check if each feature overlapped by the query range
tibble_vertices_with_pct_overlap <- tibble_vertices_with_pct_overlap %>%
dplyr::mutate("is_overlapped" = ((query_vertex + input$workshop_left_query_end_shift %>% type.convert - input$workshop_left_match_tolerance %>% type.convert) <= ref_exon_end) & ((query_vertex + input$workshop_left_query_end_shift %>% type.convert - input$workshop_left_match_tolerance %>% type.convert) >= ref_exon_start)
)
tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == TRUE, "pct_overlap"] <- tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == TRUE, ] %>% ( function(x) {100 * abs(x$query_vertex - x$ref_vertex)/(x$ref_exon_end - x$ref_exon_start) %>% return} )
tibble_vertices_with_pct_overlap[tibble_vertices_with_pct_overlap$is_overlapped == FALSE, "pct_overlap"] <- 0
return(tibble_vertices_with_pct_overlap)
} ) %>% dplyr::bind_rows() %>% unique
}
# make the distances directional
tibble_distance_annotations_based_on_user_query <- tibble_distance_annotations_based_on_user_query %>%
dplyr::mutate("ref_vertex_minus_query_vertex" = purrr::map(.x = `ref_vertex_minus_query_vertex`, .f = function(x) {
if (x < 0) {
return(paste(abs(x), ">", sep = ""))
} else if (x > 0) {
return(paste("<", abs(x), sep = ""))
} else {
return(x)
}
} ) %>% unlist  )
tibble_distance_annotations_based_on_user_query$panel <- a2
} else {
tibble_distance_annotations_based_on_user_query <- tibble()
tibble_all_exons_of_overlapped_parent_transcript <- tibble()
}
# invoke tolerances
# tibble_selected_range_measurement_against_reference[abs(tibble_selected_range_measurement_against_reference$distance_to_ref) <= 1, "distance_to_ref"] <- 0
##########
return(
list(
"tibble_distance_annotations_based_on_user_query" = tibble_distance_annotations_based_on_user_query,
"tibble_all_exons_of_overlapped_parent_transcript" = tibble_all_exons_of_overlapped_parent_transcript
)
)
} ) %>% suppressWarnings()
list_distances_between_user_ranges_and_reference_annotations <- list_distance_annotation_data_flattened %>% purrr::map(~.x$tibble_distance_annotations_based_on_user_query) %>% purrr::keep(.p = ~.x %>% length > 0)
list_distances_between_user_ranges_and_reference_annotations
list_distance_annotation_data_flattened
list_distance_annotation_data_flattened
list_tibbles_track_features_visible_flattened
list_tibbles_track_features_visible_flattened <- global_2_list_tibbles_track_features_visible_flattened
list_tibbles_track_features_visible_flattened[grep(x = names(list_tibbles_track_features_visible_flattened), pattern = "^Reference transcripts")]
list_tibbles_track_features_visible_flattened[grep(x = names(list_tibbles_track_features_visible_flattened), pattern = "^Reference transcripts")] %>% .[[1]]
a1 <- list_tibbles_track_features_visible_flattened[grep(x = names(list_tibbles_track_features_visible_flattened), pattern = "^Reference transcripts")] %>% .[[1]]
ggplot() +
geom_segment(data = a1 %>% dplyr::filter(type == "transcript"), colour = "slateblue1", mapping = aes(x = start, xend = end, y = transcript_id, yend = transcript_id))
ggplot() +
geom_text(data = a1 %>% dplyr::filter(type == "transcript"), nudge_y = 0.5, fontface = "italic", mapping = aes(x = mean(workshop_plot_brush_ranges$x), y = transcript_id, label = purrr::pmap(.l = list("b1" = strand, "b2" = hgnc_stable_transcript_ID, "b3" = transcript_version), .f = function(b1, b2, b3) {if (b1 == "+") {paste("> > > > > > ", b2, " > > > > > >", sep = "")} else if (b1 == "-") {paste("< < < < < < ", b2, " < < < < < <", sep = "")} else {b2} } ) %>% unlist))
global_workshop_reactiveValues_plot_metadata
ggplot() +
geom_text(data = a1 %>% dplyr::filter(type == "transcript"), nudge_y = 0.5, fontface = "italic", mapping = aes(x = 1, y = transcript_id, label = purrr::pmap(.l = list("b1" = strand, "b2" = hgnc_stable_transcript_ID, "b3" = transcript_version), .f = function(b1, b2, b3) {if (b1 == "+") {paste("> > > > > > ", b2, " > > > > > >", sep = "")} else if (b1 == "-") {paste("< < < < < < ", b2, " < < < < < <", sep = "")} else {b2} } ) %>% unlist))
ggplot() +
geom_tile(data = a1 %>% dplyr::filter(type == "exon"), fill = "slateblue1", mapping = aes(x = 0.5*(start + end), width = end - start + 1, y = transcript_id, height = 0.1))
a1 %>% dplyr::filter(type == "exon")
runApp('/mnt/LTS/projects/2020_isoform_nomenclature/nomenclature_app/app_native/EDN_suite')
