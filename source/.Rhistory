## for rows where diff > 1, the n represents the end of an exon. n.plus.1 represents the start of the exon right after the gap.
tibble_n_n.plus.1 <- tibble("n" = vector_genome_relative_feature_positions %>% head(n = length(vector_genome_relative_feature_positions) - 1),
"n.plus.1" = vector_genome_relative_feature_positions %>% .[2:length(vector_genome_relative_feature_positions)]) %>%
add_column("difference" = .$n.plus.1 - .$n)
## if there are no gaps, then just take the genomic range as the start:end
if (tibble_n_n.plus.1$difference %>% unique %>% length == 1) {
vec_starts <- min(vector_genome_relative_feature_positions)
vec_ends <- max(vector_genome_relative_feature_positions)
vec_widths <- vec_ends - vec_starts + 1
} else if (tibble_n_n.plus.1$difference %>% unique %>% length > 1) {
# vec_blockCount <- tibble_n_n.plus.1$difference %>% unique %>% length
vec_starts <- c(first(vector_genome_relative_feature_positions),
tibble_n_n.plus.1[tibble_n_n.plus.1$difference > 1, "n.plus.1"] %>% unlist(use.names = FALSE))
vec_ends <- c(tibble_n_n.plus.1[tibble_n_n.plus.1$difference > 1, "n"] %>% unlist(use.names = FALSE),
last(vector_genome_relative_feature_positions))
vec_widths <- vec_ends - vec_starts + 1
}
tibble_gtf_entries <- b1 %>%
dplyr::select(-vec_all_genome_relative_coords_of_item, -nucleotide_width) %>%
dplyr::bind_cols(
.,
tibble(
"start" = vec_starts,
"end" = vec_ends,
"width" = vec_widths,
"type" = "exon") )
} )
return(list_biomart_regions_gtf)
}, .progress = TRUE )
) )
save(list_biomart_regions_cast_onto_genome_split, file = paste(results_dir, "list_biomart_regions_cast_onto_genome_split.Rlist", sep = ""), compress = FALSE)
detach("package:furrr", unload = TRUE)
detach("package:future", unload = TRUE)
library(furrr)
options(future.globals.maxSize = 30000000000, future.fork.enable = TRUE)
plan(multiprocess)
memory.limit(100000)
plan(list(tweak(multiprocess, workers = 30),
tweak(multiprocess, workers = 4))
)
## subset by protein (+ version) in order to create a "transcript" of all its PTMs.
suppressWarnings( suppressMessages(
list_biomart_regions_gtf <- furrr::future_imap(
.x = list_biomart_regions_cast_onto_genome_split,
.f = function(a1, a2) {
# DEBUG ###
# a1 <- list_biomart_regions_cast_onto_genome_split[[1]]
###########
cat(a2, "L1 \n")
L1_split_list <- a1 %>% dplyr::rowwise() %>% dplyr::group_split()
list_biomart_regions_gtf <- furrr::future_imap(
.x = L1_split_list,
.f = function(b1, b2) {
# DEBUG ###
# b1 <- tibble_biomart_regions_cast_onto_genome %>% dplyr::rowwise() %>% dplyr::group_split() %>% .[[1]]
###########
cat(b2, "L2 \n")
vector_genome_relative_feature_positions <- b1$vec_all_genome_relative_coords_of_item %>% unlist %>% sort
# convert the individual nt positions to a set of ranges
## achieve this by comparing n to n + 1
## for rows where diff > 1, the n represents the end of an exon. n.plus.1 represents the start of the exon right after the gap.
tibble_n_n.plus.1 <- tibble("n" = vector_genome_relative_feature_positions %>% head(n = length(vector_genome_relative_feature_positions) - 1),
"n.plus.1" = vector_genome_relative_feature_positions %>% .[2:length(vector_genome_relative_feature_positions)]) %>%
add_column("difference" = .$n.plus.1 - .$n)
## if there are no gaps, then just take the genomic range as the start:end
if (tibble_n_n.plus.1$difference %>% unique %>% length == 1) {
vec_starts <- min(vector_genome_relative_feature_positions)
vec_ends <- max(vector_genome_relative_feature_positions)
vec_widths <- vec_ends - vec_starts + 1
} else if (tibble_n_n.plus.1$difference %>% unique %>% length > 1) {
# vec_blockCount <- tibble_n_n.plus.1$difference %>% unique %>% length
vec_starts <- c(first(vector_genome_relative_feature_positions),
tibble_n_n.plus.1[tibble_n_n.plus.1$difference > 1, "n.plus.1"] %>% unlist(use.names = FALSE))
vec_ends <- c(tibble_n_n.plus.1[tibble_n_n.plus.1$difference > 1, "n"] %>% unlist(use.names = FALSE),
last(vector_genome_relative_feature_positions))
vec_widths <- vec_ends - vec_starts + 1
}
tibble_gtf_entries <- b1 %>%
dplyr::select(-vec_all_genome_relative_coords_of_item, -nucleotide_width) %>%
dplyr::bind_cols(
.,
tibble(
"start" = vec_starts,
"end" = vec_ends,
"width" = vec_widths,
"type" = "exon") )
} )
return(list_biomart_regions_gtf)
}, .progress = TRUE )
) )
library(tidyverse)
library(gtools)
library(extrafont)
# font_import(paths = "~/.local/share/fonts/")
loadfonts(device = "pdf")
# windowsFonts("Helvetica" = windowsFont("Helvetica"))
library(RColorBrewer)
library(genefilter)
library(ggplot2)
library(ggpattern)
library(plotly)
library(kohonen)
library(genefilter)
# library(gplots)
# library(lattice)
library(svglite)
library(scales)
library(furrr)
options(future.globals.maxSize = 30000000000, future.fork.enable = TRUE)
plan(multiprocess)
memory.limit(100000)
library(data.table)
# library(crayon)
# library(VennDiagram)
library(biomaRt)
httr::set_config(httr::config(ssl_verifypeer = FALSE))
ensembl_archive_name <- "sep2019"
ensembl_mart = useMart(biomart = "ensembl", dataset = "hsapiens_gene_ensembl", host = paste("http://", ensembl_archive_name, ".archive.ensembl.org", sep = ""))
# library(systemPipeR)
# library(GOstats)
# library(PFAM.db)
# library(bc3net)
# library(ComplexHeatmap)
library(ggdendro)
library(data.table)
# library(Rfast)
reference_data_dir <- "/mnt/LTS/reference_data/"
app_data_dir <- "/mnt/LTS/projects/2020_isoform_nomenclature/nomenclature_app/app_native/EDN_suite/data/"
results_dir <- "/mnt/LTS/projects/2020_isoform_nomenclature/results_multiomic_track_annotations/"
# ucsc_hg19_to_hg38_chainfile_path <- "/mnt/Tertiary/sharedfolder/hg38_ensembl_reference/hg19ToHg38.over.chain"
# function to do Benjamini-Hochberg FDR correction for Gene Ontology output tables from GOHyperGall
## takes the output of the GOHyperGall GO enrichment table and over-writes the Padj column with benjamini-corrected values from the Phyper column
## spits out the resulting table with modified single column.
## NOTE: BENJAMINI PVALUES ABOVE 0.05 ARE RENAMED NA
GOHyperGAll_benjamini_correction <- function(raw_GOHyperGAll_table)
{
benjamini_GOHyperGAll_table <- raw_GOHyperGAll_table
benjamini_GOHyperGAll_table <- benjamini_GOHyperGAll_table[benjamini_GOHyperGAll_table$SampleMatch > 1, ]
if (benjamini_GOHyperGAll_table %>% nrow == 0) {
benjamini_GOHyperGAll_table <- tibble()
} else {
benjamini_GOHyperGAll_table[, "Padj"] <- p.adjust(p = benjamini_GOHyperGAll_table[, "Phyper"], method = "BH", n = length(benjamini_GOHyperGAll_table[, "Phyper"]))
# benjamini_GOHyperGAll_table[benjamini_GOHyperGAll_table$Padj > 0.05, "Padj"] <- NA
}
return(benjamini_GOHyperGAll_table)
}
# the equivalent for bc3net::enrichment() output table
bc3net_benjamini_correction <- function(raw_bc3net_table)
{
benjamini_bc3net_table <- raw_bc3net_table
benjamini_bc3net_table_processed <- benjamini_bc3net_table[benjamini_bc3net_table$genes > 1, ]
if (nrow(benjamini_bc3net_table_processed) != 0) {
benjamini_bc3net_table_processed[, "padj"] <- p.adjust(p = benjamini_bc3net_table_processed[, "pval"], method = "BH", n = length(benjamini_bc3net_table_processed[, "pval"]))
# benjamini_bc3net_table_processed[benjamini_bc3net_table_processed$padj > 0.05, "padj"] <- NA
} else {
benjamini_bc3net_table_processed <- benjamini_bc3net_table
benjamini_bc3net_table_processed[, "padj"] <- NA
}
return(benjamini_bc3net_table_processed)
}
# bc3net::enrichment() does not show captured genes for each family enriched, so we have to add it in. but in doing so, i want to avoid a purrr within a purrr
# this function selects genes from the background in each family which are ONLY input genes.
filtering_genehits_from_background_catalogue <- function(catalogue, genehit_vector){
filtered_catalogue <- purrr::map(.x = catalogue, .f = ~intersect(.x, genehit_vector))
return(filtered_catalogue)
}
# FUNCTION TO EXTRACT TRANSCRIPTS WITH JUNCTION-FLANKING EXONS.
# NOTE: to be used with purrr
# details of ONE junction: $chr, $start, $end, $strand
# tibble_gtf_table: rtracklayer::import(...) %>% as_tibble. can be any GTF. reconstructed or reference.
# index: loop progress marker to be used with imap
extract_junction.flanking.exons <- function(query_chr, query_start, query_end, query_strand, tibble_gtf_table, tolerance_left = 1, tolerance_right = 1, tolerance_inside = 1, tolerance_outside = 0, match_consecutive = TRUE, return_type = "exon") {
# DEBUG ###
# query_chr = b1$chr
# query_start = b1$vector_alt_segment_starts
# query_end = b1$vector_alt_segment_ends
# query_strand = "*"
# tibble_gtf_table = a2
# tolerance_left = 0
# tolerance_right = 0
# tolerance_inside = 0
# tolerance_outside = 0
# match_consecutive = TRUE
# return_type = ".*"
###########################
# print(paste("now processing junction number", index))
if (query_strand == "." | query_strand == 0 | query_strand == "*") {
tibble_gtf_subset_flanking_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>% .[.$start <= ((query_end %>% type.convert) + 1 + tolerance_outside + tolerance_left) & .$end >= ((query_start %>% type.convert) - 1 - tolerance_outside - tolerance_left), ] %>% .[!(.$start <= ((query_end %>% type.convert) - tolerance_inside - tolerance_right) & .$end >= ((query_start %>% type.convert) + tolerance_inside + tolerance_left)), ]
} else if (query_strand == "+" | query_strand == "-") {
tibble_gtf_subset_flanking_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>% .[.$strand == query_strand %>% trimws, ] %>% .[.$start <= ((query_end %>% type.convert) + 1 + tolerance_right) & .$end >= ((query_start %>% type.convert) - 1 - tolerance_left), ] %>% .[!(.$start <= ((query_end %>% type.convert) - tolerance_inside - tolerance_right) & .$end >= ((query_start %>% type.convert) + tolerance_inside + tolerance_left)), ]
} else {
stop("Could not match the strand information in the transposed differential-only UNION_junc_coor_table. Make sure that the \"strand\" column in the UNION_junc_coor_table contains only +, - or .")
}
if (tibble_gtf_subset_flanking_exons %>% nrow > 0) {
tibble_gtf_subset_flanking_exons <- tibble_gtf_subset_flanking_exons %>% dplyr::filter(str_detect(string = `type`, pattern = return_type))
}
list_of_junction_associated_transcripts <- tibble_gtf_subset_flanking_exons$transcript_id %>% unique %>% array_tree %>% flatten
# make a list for each transcript that directly flanks a junction.
# then filter so that there are only a) exon PAIRS which b) are directly connected in the mature (spliced) transcript
if (match_consecutive == TRUE) {
list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% type.convert)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2) %>% keep(.x = ., .p = ~abs((.x[2, "exon_number"] %>% paste %>% type.convert) - (.x[1, "exon_number"] %>% paste %>% type.convert)) == 1)
} else if (match_consecutive == FALSE) {
list_of_tibbles_flanking_exon_gtf.entries_per_transcript <- purrr::map(.x = list_of_junction_associated_transcripts, .f = ~tibble_gtf_subset_flanking_exons[tibble_gtf_subset_flanking_exons$transcript_id == .x, ] %>% dplyr::arrange(exon_number %>% type.convert)) %>% set_names(list_of_junction_associated_transcripts) %>% keep(.x = ., .p = ~nrow(.x) == 2)
}
return(list_of_tibbles_flanking_exon_gtf.entries_per_transcript)
}
# END extract_junction.flanking.exons_JUM() ###
# FUNCTION TO EXTRACT REFERENCE EXONS WHICH OVERLAP EXACTLY WITH QUERY EXONS
# NOTE: to be used with purrr
# input: spliceregion_list: a list containing details of ONE junction: $chr, $vector_alt_segment_starts, $vector_alt_segment_ends
# tibble_gtf_table: rtracklayer::import(...) %>% as_tibble. can be any GTF. reconstructed or reference.
# index: loop progress marker to be used with imap
extract_matching.exons <- function(query_chr, query_start, query_end, query_strand, tibble_gtf_table, tolerance_left = 0, tolerance_right = 0, tolerance_inside = 0, tolerance_outside = 0, return_type = "exon") {
# DEBUG ###################
# index <- 1
# spliceregion_list <- wide_tibble_of_all_unique_VSR_and_exon_coords_array.tree_not_IR[[index]]
# # tibble_gtf_table <- tibble_ref_gtf
# tibble_gtf_table <- tibble_recon_gtf
# stranded = FALSE
###########################
# print(paste("now processing junction number", index))
if (query_strand == "." | query_strand == 0 | query_strand == "*") {
# +/- 1 nt tolerance
tibble_gtf_subset_overlapping_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>%
.[which(.$start > ((query_start %>% as.numeric) - 1 - tolerance_left - tolerance_outside) & .$end < ((query_end %>% as.numeric) + 1 + tolerance_right + tolerance_outside)), ] %>%
.[which((.$start < ((query_start %>% as.numeric) + 1 + tolerance_left + tolerance_inside) & .$end > ((query_end %>% as.numeric) - 1 - tolerance_right - tolerance_inside))), ] %>%
.[which(.$type == return_type), ]
} else if (query_strand == "+" | query_strand == "-") {
# +/- 1 nt tolerance
tibble_gtf_subset_overlapping_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws &
tibble_gtf_table$strand == query_strand %>% trimws, ] %>%
.[which(.$start > ((query_start %>% as.numeric) - 1 - tolerance_left - tolerance_outside) & .$end < ((query_end %>% as.numeric) + 1 + tolerance_right + tolerance_outside)), ] %>%
.[which((.$start < ((query_start %>% as.numeric) + 1 + tolerance_left + tolerance_inside) & .$end > ((query_end %>% as.numeric) - 1 - tolerance_right - tolerance_inside))), ] %>%
.[which(.$type == return_type), ]
} else {
stop("Could not match the strand information in the transposed differential-only UNION_junc_coor_table. Make sure that the \"strand\" column in the UNION_junc_coor_table contains only +, - or .")
}
return(tibble_gtf_subset_overlapping_exons)
}
extract_overlapping_features <- function(query_chr, query_start, query_end, query_strand, tibble_gtf_table, left_query_shift = 0, right_query_shift = 0, left_tolerance = 0, right_tolerance = 0, return_type) {
# DEBUG ###################
# index <- 1
# spliceregion_list <- wide_tibble_of_all_unique_VSR_and_exon_coords_array.tree_not_IR[[index]]
# # tibble_gtf_table <- tibble_ref_gtf
# tibble_gtf_table <- tibble_recon_gtf
# stranded = FALSE
###########################
# cat(query_chr, "\n")
# cat(query_start, "\n")
# cat(query_end, "\n")
# cat(query_strand, "\n")
# print(tibble_gtf_table, "\n")
# cat(left_query_shift, "\n")
# cat(right_query_shift, "\n")
# cat(left_tolerance, "\n")
# cat(right_tolerance, "\n")
# print(paste("now processing junction number", index))
# left_query_shift <<- left_query_shift
# right_query_shift <<- right_query_shift
# left_tolerance <<- left_tolerance
# right_tolerance <<- right_tolerance
if (!(query_strand == "+" | query_strand == "-")) {
# +/- 1 nt tolerance
tibble_gtf_subset_matching_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws, ] %>%
.[which(.$end >= ((query_start %>% as.numeric) + left_query_shift - left_tolerance) & .$start <= ((query_end %>% as.numeric) + right_query_shift + right_tolerance)), ] %>%
.[which(.$type == return_type), ]
} else if (query_strand == "+" | query_strand == "-") {
# +/- 1 nt tolerance
tibble_gtf_subset_matching_exons <- tibble_gtf_table[tibble_gtf_table$seqnames == query_chr %>% trimws &
tibble_gtf_table$strand == query_strand %>% trimws, ] %>%
.[which(.$end >= ((query_start %>% as.numeric) + left_query_shift - left_tolerance) & .$start <= ((query_end %>% as.numeric) + right_query_shift + right_tolerance)), ] %>%
.[which(.$type == return_type), ]
}
return(tibble_gtf_subset_matching_exons)
}
## END extract_overlapping_features() ###
# FUNCTION TO EXTRACT COMMON STRING FROM TWO INPUT STRINGS IN ONE STEP, A SIMPLIFICATION OF QUALV
extract_common_string <- function(input_string_a, input_string_b) {
# debug ###
#
# input_string_a <- "ud_absolute.psi_1"
# input_string_b <- "ud_absolute.psi_2"
###########
vector_of_letters_a <- strsplit(input_string_a, "") %>% unlist
vector_of_letters_b <- strsplit(input_string_b, "") %>% unlist
raw_LCS <- qualV::LCS(vector_of_letters_a, vector_of_letters_b)
vector_common_string <- raw_LCS$LCS %>% paste(collapse = "")
return(vector_common_string)
}
# END extract_common_string()
# FUNCTION TO TAKE THE AVERAGE VALUE OF A MATRIX OF TIMEPOINTS WITH THREE REPLICATES EACH (3 column compartments at a time)
## replicates of the same timepoint must be all grouped together.
calculate_average_values_from_replicate_columns <- function(input_matrix, number_of_replicates, append_average_to_column_name = TRUE) {
# DEBUG ######
# input_matrix <- wide_tibble_of_psisigma_results_allcomparisons_final_ud.only[, col_indices_observations]
# number_of_replicates <- 3
##############
# sanity check - if the number of columns is not an integer multiple of the number of replicates, there's something wrong
if (ncol(input_matrix) %% number_of_replicates != 0) {
stop("the number of columns in the matrix is not an integer multiple of the number of replicates specified. please check the matrix and try again.")
}
# get the row numbers to subset
## start of each compartment
a <- seq(1, (ncol(input_matrix) - number_of_replicates + 1), number_of_replicates)
## end of each compartment
b <- seq(number_of_replicates, ncol(input_matrix), number_of_replicates)
# create list of compartments
c <- purrr::map2(.x = a, .y = b, .f = ~.x:.y)
# map each column into each compartment
d <- purrr::map(.x = c, .f = ~input_matrix[, .x])
# apply the average
e <- purrr::map(.x = d, .f = ~apply(X = .x, MARGIN = 1, FUN = function(X){mean(X, na.rm = TRUE)}))
# retrieve the column names of each compartment
column_names <- purrr::map(.x = d, .f = ~colnames(.x) %>% purrr::reduce(extract_common_string))
if (append_average_to_column_name == TRUE) {
column_names <- paste(column_names, "average", sep = "")
}
# reframe into tibble, return
f <- e %>% set_names(column_names) %>% as_tibble
}
# END calculate_average_values_from_replicate_columns()
plot_PCA_for_timepoint_and_replicate <- function(matrixtable, timepoint_order = NULL, replicate_order = NULL, plot_shapes = TRUE, text_labels = FALSE, point_or_label_size = 2, legend_position = "right", PCA_depths_y = NULL, PCA_depths_x = NULL, save_dir = NULL, save_name = NULL, graph_title = NULL, width = 10, height = 10) {
# DEBUG ###
# matrixtable <- wide_tibble_matrix_processed_sorted_tibbles %>% as.data.frame
# save_dir <- R_processing_results_dir
# save_name <- "total_RNA"  #
# graph_title <- "Total RNA"  #
# timepoint_order <- long_tibble_processed_sorted_tibbles$sample_name %>% unique
# replicate_order <- c("r1", "r2", "r3", "r4", "r5", "r6", "r7", "r8")
# width = 10
# height = 10
# PCA_depths_y = c(2, 3, 4)
# PCA_depths_x = c(1, 2, 3)
# text_labels <- FALSE
# point_or_label_size <- 4
###########
PCA_result <- prcomp(matrixtable)
## measure PC variance #
PCA_stdev <- tibble("PC" = 1:(PCA_result[["sdev"]] %>% length), "stdev" = PCA_result[["sdev"]])
PCA_variance <- tibble(PC = PCA_stdev$PC, variance = PCA_stdev$stdev ^ 2)
PCA_variance <- add_column(PCA_variance, variance_explained = PCA_variance$variance/sum(PCA_variance$variance) * 100)
ggplot(PCA_variance) +
geom_col(aes(x = PC, y = variance_explained, fill = PC)) +
scale_fill_gradientn(colours = heat.colors(n = (PCA_result[["sdev"]] %>% length))) +
ggtitle(paste("PCA variance distribution\n", graph_title, sep = "")) +
guides(size = FALSE) +
xlab("PC") +
ylab("Variance explained (%)") +
theme_bw() +
theme(text = element_text(family = "Helvetica")) +
ggsave(filename = paste(save_dir, "PCA_barplot_stdevs_", save_name, ".pdf", sep = ""), device = "pdf", dpi = 600, width = 45, height = 25, units = "cm") +
ggsave(filename = paste(save_dir, "PCA_barplot_stdevs_", save_name, ".svg", sep = ""), device = "svg", dpi = 600, width = 45, height = 25, units = "cm")
## measure PC loadings #
## column names of the matrix need to be split by a "|", like this: timepoint|replicatenumber
PCA_loadings <- PCA_result[["rotation"]] %>% as_tibble(rownames = "sample")
PCA_loadings <- add_column(PCA_loadings, "timepoint" = gsub(x = PCA_loadings$sample, pattern = "(.*)\\|(.*)", replacement = "\\1") %>% factor(x = ., levels = timepoint_order), .after = "sample")
PCA_loadings <- add_column(PCA_loadings, "replicatenumber" = gsub(x = PCA_loadings$sample, pattern = "(.*)\\|(.*)", replacement = "\\2") %>% factor(x = ., levels = replicate_order), .after = "sample")
PCA_loadings <- add_column(PCA_loadings,
"condition_names" = gsub(x = PCA_loadings$sample, pattern = "(.*)\\|(.*)", replacement = "\\1"),
"replicate_names" = gsub(x = PCA_loadings$sample, pattern = "(.*)\\|(.*)", replacement = "\\2"),
.after = "sample")
# append cluster number according to the order of timepoints specified by the user
PCA_loadings <- dplyr::left_join(PCA_loadings, tibble("condition_names" = levels(PCA_loadings$timepoint), "cluster_number" = 1:length(levels(PCA_loadings$timepoint))), by = "condition_names") %>%
dplyr::relocate(cluster_number, .after = "sample")
# plot PCA for multiple depths all in one go.
purrr::map2(.x = PCA_depths_x, .y = PCA_depths_y, .f = function(.x, .y) {
pc_x <- .x
pc_y <- .y
ggplot(PCA_loadings) +
(if (text_labels == FALSE) {geom_point(aes(x = !!(paste("PC", pc_x, sep = "") %>% as.name), y = !!(paste("PC", pc_y, sep = "") %>% as.name), shape = replicatenumber, color = timepoint), size = point_or_label_size)} else if (text_labels == TRUE) {geom_text(aes(x = !!(paste("PC", pc_x, sep = "") %>% as.name), y = !!(paste("PC", pc_y, sep = "") %>% as.name), label = PCA_loadings$cluster_number, color = timepoint), size = point_or_label_size, position = position_dodge(width = 4))}) +
scale_color_brewer(name = "Timepoint", palette = "Spectral", breaks = timepoint_order, limits = timepoint_order) +
scale_shape_manual(name = "Replicate", values = 1:length(replicate_order)) +
ggtitle(paste("PCA loadings\n", graph_title, sep = "")) +
guides(size = FALSE) +
xlab(paste("PC", pc_x, " (", PCA_variance[pc_x, "variance_explained"] %>% signif(3), "%)", sep = "")) +
ylab(paste("PC", pc_y, " (", PCA_variance[pc_y, "variance_explained"] %>% signif(3), "%)", sep = "")) +
theme_bw() +
theme(text = element_text(family = "Helvetica"), legend.position = legend_position) +
ggsave(filename = paste(save_dir, "PCA_loadings_", save_name, "_PC", pc_y, "_vs_PC_", pc_x, ".pdf", sep = ""), device = "pdf", dpi = 600, width = width, height = height, units = "cm") +
ggsave(filename = paste(save_dir, "PCA_loadings_", save_name, "_PC", pc_y, "_vs_PC_", pc_x, ".svg", sep = ""), device = "svg", dpi = 600, width = width, height = height, units = "cm")
} )
}
plot_UMAP_for_timepoint_and_replicate <- function(transposed_matrixtable, timepoint_order = NULL, replicate_order = NULL, plot_shapes = TRUE, centroid_labels = TRUE, point_size = 5, centroid_label_size = 4, legend_position = "none", PCA_depths_y = NULL, PCA_depths_x = NULL, input_colour_limits = NULL, input_colour_value = NULL, save_dir = NULL, save_name = NULL, graph_title = NULL, width = 10, height = 10) {
# DEBUG ###
# transposed_matrixtable <- df_matrix_absolute_psi_in_sample_replicate_format %>% na.omit %>% t
# timepoint_order <- temp_condition_names
# replicate_order <- c("r1", "r2", "r3", "r4", "r5", "r6", "r7", "r8")
# plot_shapes <- FALSE
# legend_position <- "none"
# centroid_labels <- TRUE
# point_size <- 1
# centroid_label_size <- 1
# PCA_depths_y <- c(2, 3, 4)
# PCA_depths_x <- c(1, 2, 3)
# save_dir <- R_processing_results_dir
# save_name <- "total_RNA_psisigma_pooled_replicates_no_na"
# graph_title <- "Total RNA/PSI-Sigma"
# width <- 40
# height <- 40
###########
tibble_umap_result <- umap::umap(transposed_matrixtable) %>% .$layout %>%
as_tibble(rownames = "condition|replicate", .name_repair = "unique") %>%
setNames(nm = c("condition|replicate", "V1", "V2")) %>%
add_column("condition_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\1"),
"replicate_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\2")
)
# centroid labels: make a separate file containing the centroid locations
tibble_centroid_locations <- tibble_umap_result %>%
dplyr::group_by(condition_names) %>%
dplyr::summarise("centroid_x" = mean(V1),
"centroid_y" = mean(V2)) %>%
add_column("cluster_number" = paste(1:nrow(.)), .after = "condition_names")
# append cluster info
tibble_umap_result_plot <- dplyr::left_join(tibble_umap_result, tibble_centroid_locations, by = "condition_names")
if (is.null(input_colour_limits) == TRUE) {
input_colour_limits <- c(tibble_umap_result_plot$condition_names %>% unique)
}
if (is.null(input_colour_value) == TRUE) {
input_colour_value <- rainbow(n = (timepoint_order %>% length))
}
# plot UMAP for multiple depths all in one go.
ggplot() +
(if (plot_shapes == TRUE) {geom_point(aes(x = tibble_umap_result_plot$V1, y = tibble_umap_result_plot$V2, shape = tibble_umap_result_plot$replicate_names, color = tibble_umap_result_plot$condition_names, fill = tibble_umap_result_plot$condition_names), size = point_size) } else {geom_blank(aes(x = tibble_umap_result_plot$V1, y = tibble_umap_result_plot$V2))}) +
scale_shape_manual(name = "Replicate", values = 1:length(replicate_order)) +
(if (centroid_labels == TRUE) {geom_text(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y, label = tibble_centroid_locations$cluster_number, color = tibble_centroid_locations$condition_names), size = centroid_label_size)} else {geom_blank(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y))}) +
scale_fill_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
scale_colour_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
# scale_color_brewer(name = "Timepoint", palette = "Spectral", breaks = timepoint_order, limits = timepoint_order) +
ggtitle(paste("UMAP projection\n", graph_title, sep = "")) +
guides(size = FALSE) +
xlab("UMAP_1") +
ylab("UMAP_2") +
theme_bw() +
theme(text = element_text(family = "Helvetica"), legend.position = legend_position) +
ggsave(filename = paste(save_dir, "UMAP_", save_name, ".pdf", sep = ""), device = "pdf", dpi = 600, width = width, height = height, units = "cm") +
ggsave(filename = paste(save_dir, "UMAP_", save_name, ".svg", sep = ""), device = "svg", dpi = 600, width = width, height = height, units = "cm")
write.table(x = tibble_centroid_locations, file = paste(save_dir, "UMAP_", save_name, "_cluster_legend.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)
}
plot_tSNE_for_timepoint_and_replicate <- function(transposed_matrixtable, timepoint_order = NULL, replicate_order = NULL, plot_shapes = TRUE, centroid_labels = TRUE, point_size = 5, centroid_label_size = 4, legend_position = "none", PCA_depths_y = NULL, PCA_depths_x = NULL, input_colour_limits = NULL, input_colour_value = NULL, save_dir = NULL, save_name = NULL, graph_title = NULL, width = 10, height = 10) {
# DEBUG ###
# transposed_matrixtable <- wide_tibble_matrix_processed_sorted_tibbles %>% as.data.frame %>% t
# save_dir <- R_processing_results_dir
# save_name <- "total_RNA"
# graph_title <- "Total RNA"
# timepoint_order <- long_tibble_processed_sorted_tibbles$sample_name %>% unique
# replicate_order <- c("r1", "r2", "r3", "r4", "r5", "r6", "r7", "r8")
# width <- 40
# height <- 40
# point_size <- 1
# centroid_label_size <- 1
# plot_shapes <- FALSE
# centroid_labels <- TRUE
# legend_position <- "none"
###########
tibble_tsne_result <- Rtsne::Rtsne(X = transposed_matrixtable %>% unique, perplexity = 1, check_duplicates = FALSE, verbose = TRUE, num_threads = 0) %>% .$Y %>%
as_tibble(.name_repair = "unique") %>%
add_column("condition_names" = rownames(transposed_matrixtable %>% unique), .before = 1) %>%
setNames(nm = c("condition|replicate", "V1", "V2")) %>%
add_column("condition_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\1"),
"replicate_names" = gsub(x = .$`condition|replicate`, pattern = "(.*)\\|(.*)", replacement = "\\2")
)
# centroid labels: make a separate file containing the centroid locations
tibble_centroid_locations <- tibble_tsne_result %>%
dplyr::group_by(condition_names) %>%
dplyr::summarise("centroid_x" = mean(V1),
"centroid_y" = mean(V2)) %>%
add_column("cluster_number" = paste(1:nrow(.)), .after = "condition_names")
# append cluster info
tibble_tsne_result_plot <- dplyr::left_join(tibble_tsne_result, tibble_centroid_locations, by = "condition_names")
if (is.null(input_colour_limits) == TRUE) {
input_colour_limits <- c(tibble_tsne_result_plot$condition_names %>% unique)
}
if (is.null(input_colour_value) == TRUE) {
input_colour_value <- rainbow(n = (timepoint_order %>% length))
}
# plot UMAP for multiple depths all in one go.
ggplot() +
(if (plot_shapes == TRUE) {geom_point(aes(x = tibble_tsne_result_plot$V1, y = tibble_tsne_result_plot$V2, shape = tibble_tsne_result_plot$replicate_names, color = tibble_tsne_result_plot$condition_names, fill = tibble_tsne_result_plot$condition_names), size = point_size) } else {geom_blank(aes(x = tibble_tsne_result_plot$V1, y = tibble_tsne_result_plot$V2))}) +
scale_shape_manual(name = "Replicate", values = 1:length(replicate_order)) +
(if (centroid_labels == TRUE) {geom_text(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y, label = tibble_centroid_locations$cluster_number, color = tibble_centroid_locations$condition_names), size = centroid_label_size)} else {geom_blank(aes(x = tibble_centroid_locations$centroid_x, y = tibble_centroid_locations$centroid_y))}) +
scale_fill_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
scale_colour_manual(name = "Timepoint", breaks = input_colour_limits, limits = input_colour_limits, values = input_colour_value) +
# scale_color_brewer(name = "Timepoint", palette = "Spectral", breaks = timepoint_order, limits = timepoint_order) +
ggtitle(paste("tSNE projection\n", graph_title, sep = "")) +
guides(size = FALSE) +
xlab("tSNE_1") +
ylab("tSNE_2") +
theme_bw() +
theme(text = element_text(family = "Helvetica"), legend.position = legend_position) +
ggsave(filename = paste(save_dir, "tSNE_", save_name, ".pdf", sep = ""), device = "pdf", dpi = 600, width = width, height = height, units = "cm") +
ggsave(filename = paste(save_dir, "tSNE_", save_name, ".svg", sep = ""), device = "svg", dpi = 600, width = width, height = height, units = "cm")
write.table(x = tibble_centroid_locations, file = paste(save_dir, "tSNE_", save_name, "_cluster_legend.txt", sep = ""), sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE)
}
ensembl_GTF_dump_dir <- "/mnt/LTS/projects/2020_isoform_nomenclature/ENST_to_HGNC_stable_variant_mapping/"
interpro_archive_dir <- "/mnt/LTS/reference_data/interpro/database/ftp.ebi.ac.uk/pub/databases/interpro/"
uniprot_dir <- "/mnt/LTS/reference_data/uniprotswissprot/"
# import ensembl HGNC stable protein id mapping (gene-centric naming)
tibble_hgnc_stable_protein_id_mapping <- data.table::fread(file = paste(ensembl_GTF_dump_dir, "total_mapping_table_proteins.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, header = TRUE) %>% as_tibble
# import human uniprotkb_id to uniprot (uniparc) stable protein id mapping (protein-centric naming)
tibble_uniprot_stable_protein_id_mapping <- data.table::fread(file = paste(uniprot_dir, "uniprot_stable_protein_id_uniprotkb_entry_uniparc_mapping_human.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, header = TRUE) %>% as_tibble
# retrieve ALL ensembl GTFs in order to get a map for protein IDs.
# options(mc.cores = 24)
#
# list_all_tibble_ref_gtf <- furrr::future_map(
#   .x = list.files(path = ensembl_GTF_dump_dir, pattern = "annotated_ensembl_gtf_release", full.names = TRUE),
#   .f = ~read.delim(file = .x, sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, header = TRUE) %>% as_tibble
# ) %>% set_names(nm = list.files(path = ensembl_GTF_dump_dir, pattern = "annotated_ensembl_gtf_release", full.names = FALSE))
#
# tibble_all_ref_gtfs <- list_all_tibble_ref_gtf %>% rbindlist(use.names = TRUE, fill = FALSE) %>% as_tibble
# 38.98 only for now
# tibble_ref_gtf <- list_all_tibble_ref_gtf$annotated_ensembl_gtf_release_98.txt
tibble_ref_gtf <- data.table::fread(file = paste(ensembl_GTF_dump_dir, "annotated_ensembl_gtf_release_98.txt", sep = ""), sep = "\t", stringsAsFactors = FALSE, check.names = FALSE, header = TRUE) %>% as_tibble
